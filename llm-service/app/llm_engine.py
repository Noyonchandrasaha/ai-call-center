# Placeholder for actual LLM integration
async def generate_response(prompt: str, context: list) -> dict:
    """Mock LLM response generation"""
    return {
        "response": "I can help with that!",
        "confidence": 0.95
    }